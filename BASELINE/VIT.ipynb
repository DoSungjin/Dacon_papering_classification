{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ad9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install albumentations ;!pip3 install opencv-python ; !pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# torch.multiprocessing import\n",
    "from torch import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9614e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DoSungjin\\\\Documents\\\\GitHub\\\\Dacon_papering_classification\\\\DATA'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경로지정\n",
    "import os\n",
    "os.chdir('../DATA')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Set the device to CPU or GPU depending on availability\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':25,\n",
    "    'LEARNING_RATE':0.0001,\n",
    "    'BATCH_SIZE': 1,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {},
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abecd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DoSungjin\\\\Documents\\\\GitHub\\\\Dacon_papering_classification\\\\DATA'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "271f477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 데이터셋 디렉토리 경로\n",
    "dataset_dir = \"new_train\"\n",
    "\n",
    "# 모든 이미지 파일 경로 리스트\n",
    "all_img_list = []\n",
    "folder_list = []\n",
    "train_file_list = os.listdir(dataset_dir)\n",
    "for item in train_file_list:\n",
    "    item_path = os.path.join(dataset_dir, item)\n",
    "    for file in os.listdir(item_path):\n",
    "        all_img_list.append(os.path.join(item_path, file))\n",
    "        folder_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68163566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # folder name list\n",
    "ori_names = os.listdir('ori_train')\n",
    "\n",
    "new_names = ['furniture_repair', 'cleaning_mop_holder_repair', 'mold', 'twist', 'rust_contamination', 'wobbling', 'fabric_defect', 'molding_repair', 'stain', 'plaster_repair', 'pollution', 'typographical_error', 'crying', 'defective_joint', 'windowdoor_frame_repair', 'cracking', 'excessive_gap', 'piece', 'damage']\n",
    "\n",
    "# print(len(ori_names), len(new_names))\n",
    "# os.chdir('new_train')\n",
    "# # # folder rename\n",
    "# for ori_name, new_name in zip(ori_names, new_names):\n",
    "#     os.rename(ori_name, new_name)\n",
    "\n",
    "# print(os.listdir())\n",
    "# os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0d43a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(ori_names, new_names):\n",
    "    len_a = len(os.listdir(f'ori_train/{a}'))\n",
    "    len_b = len(os.listdir(f'new_train/{b}'))\n",
    "    if len_a == len_b:\n",
    "        print('go on')\n",
    "    else: \n",
    "        print('stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4119733d-adef-436c-afca-4112a9225d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x : str(x).split('\\\\')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb63d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\0.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\1.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\10.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\100.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\101.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>new_train\\wobbling\\53.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>new_train\\wobbling\\6.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>new_train\\wobbling\\7.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>new_train\\wobbling\\8.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>new_train\\wobbling\\9.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          img_path                       label\n",
       "0       new_train\\cleaning_mop_holder_repair\\0.png  cleaning_mop_holder_repair\n",
       "1       new_train\\cleaning_mop_holder_repair\\1.png  cleaning_mop_holder_repair\n",
       "2      new_train\\cleaning_mop_holder_repair\\10.png  cleaning_mop_holder_repair\n",
       "3     new_train\\cleaning_mop_holder_repair\\100.png  cleaning_mop_holder_repair\n",
       "4     new_train\\cleaning_mop_holder_repair\\101.png  cleaning_mop_holder_repair\n",
       "...                                            ...                         ...\n",
       "3452                     new_train\\wobbling\\53.png                    wobbling\n",
       "3453                      new_train\\wobbling\\6.png                    wobbling\n",
       "3454                      new_train\\wobbling\\7.png                    wobbling\n",
       "3455                      new_train\\wobbling\\8.png                    wobbling\n",
       "3456                      new_train\\wobbling\\9.png                    wobbling\n",
       "\n",
       "[3457 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db41c93-3515-4fcd-936b-0a01f5388b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, stratify=df['label'], random_state=CFG['SEED'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f117e-105d-4e9e-b9bd-938d4271a940",
   "metadata": {},
   "source": [
    "## Label-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8c5916-8065-4b5c-aa37-f3fb2b9fa422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>new_train\\damage\\356.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>new_train\\pollution\\137.png</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>new_train\\twist\\92.png</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>new_train\\pollution\\396.png</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>new_train\\mold\\63.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>new_train\\cracking\\105.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>new_train\\fabric_defect\\21.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>new_train\\damage\\272.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>new_train\\crying\\5.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        img_path  label\n",
       "1182                    new_train\\damage\\356.png      3\n",
       "2455                 new_train\\pollution\\137.png     12\n",
       "3226                      new_train\\twist\\92.png     15\n",
       "2742                 new_train\\pollution\\396.png     12\n",
       "2134                       new_train\\mold\\63.png      8\n",
       "...                                          ...    ...\n",
       "112   new_train\\cleaning_mop_holder_repair\\2.png      0\n",
       "315                   new_train\\cracking\\105.png      1\n",
       "1932              new_train\\fabric_defect\\21.png      6\n",
       "1089                    new_train\\damage\\272.png      3\n",
       "486                       new_train\\crying\\5.png      2\n",
       "\n",
       "[2765 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "val['label'] = le.transform(val['label'])\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "340b4a8b-5d6c-413f-b8b6-066e91a660e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.HorizontalFlip(p=0.5),  # Flip the image horizontally with probability 0.5\n",
    "    A.Rotate(limit=10, p=0.5),  # Rotate the image by -10 to 10 degrees with probability 0.5\n",
    "    A.RandomBrightnessContrast(p=0.2),  # Add random brightness and contrast with probability 0.2\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eddc330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>new_train\\damage\\356.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>new_train\\pollution\\137.png</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>new_train\\twist\\92.png</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>new_train\\pollution\\396.png</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>new_train\\mold\\63.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>new_train\\cracking\\105.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>new_train\\fabric_defect\\21.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>new_train\\damage\\272.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>new_train\\crying\\5.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        img_path  label\n",
       "1182                    new_train\\damage\\356.png      3\n",
       "2455                 new_train\\pollution\\137.png     12\n",
       "3226                      new_train\\twist\\92.png     15\n",
       "2742                 new_train\\pollution\\396.png     12\n",
       "2134                       new_train\\mold\\63.png      8\n",
       "...                                          ...    ...\n",
       "112   new_train\\cleaning_mop_holder_repair\\2.png      0\n",
       "315                   new_train\\cracking\\105.png      1\n",
       "1932              new_train\\fabric_defect\\21.png      6\n",
       "1089                    new_train\\damage\\272.png      3\n",
       "486                       new_train\\crying\\5.png      2\n",
       "\n",
       "[2765 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99f043f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['new_train\\\\damage\\\\356.png', 'new_train\\\\pollution\\\\137.png',\n",
       "       'new_train\\\\twist\\\\92.png', ...,\n",
       "       'new_train\\\\fabric_defect\\\\21.png', 'new_train\\\\damage\\\\272.png',\n",
       "       'new_train\\\\crying\\\\5.png'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['img_path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "747cd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a class for extracting embeddings via Patches of images\n",
    "class ImagePatcher(nn.Module):\n",
    "    def __init__(self,input_channels=3, patch_size=16, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        # creating the embedding layers\n",
    "        self.img_cropper_layer = nn.Conv2d(in_channels=input_channels, out_channels=embed_dim, kernel_size=patch_size, stride=patch_size, padding=0)\n",
    "        self.linear_layer = nn.Flatten(start_dim=2, end_dim=3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        image_res = x.shape[-1]\n",
    "        assert image_res% self.patch_size==0 #divisible  by 16\n",
    "\n",
    "        cropped_img_features = self.img_cropper_layer(x)\n",
    "        flattened_img_features = self.linear_layer(cropped_img_features)\n",
    "        flattened_img_features = flattened_img_features.permute(0,2,1)# as per pytorch\n",
    "\n",
    "        return flattened_img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0c45c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=768,nhead=12, dim_feedforward=2048, dropout=0.1, activation='gelu', batch_first=True, norm_first=True)\n",
    "encoder = nn.TransformerEncoder(encoder_layer=encoder_layer,num_layers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, img_size=224, num_channel=3, patch_size=16, embed_dim=768, p=0.1, num_layers=12,num_heads=12, hidden_dim=2048, num_classes=18):\n",
    "        super().__init__()\n",
    "        assert img_size%patch_size==0\n",
    "        #embedding\n",
    "        self.cropping_layer = ImagePatcher(input_channels=num_channel,patch_size=patch_size, embed_dim=embed_dim)\n",
    "\n",
    "        # class token - *\n",
    "        self.classtoken = nn.Parameter(torch.randn(1,1,embed_dim), requires_grad=True)\n",
    "\n",
    "        #positional embedding for each\n",
    "        num_patches = (img_size*img_size) //patch_size**2\n",
    "\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(1,num_patches+1, embed_dim))\n",
    "\n",
    "        #dropout\n",
    "        self.dropout = nn.Dropout(p=0.1) \n",
    "\n",
    "        #encoder \n",
    "        self.encoders = nn.TransformerEncoder(encoder_layer= nn.TransformerEncoderLayer(d_model=768,nhead=12, dim_feedforward=2048, dropout=0.1, activation='gelu', batch_first=True, norm_first=True), num_layers=num_layers)\n",
    "\n",
    "        #mlp\n",
    "        self.mlp = nn.Sequential(nn.LayerNorm(normalized_shape=embed_dim),\n",
    "                                 nn.Linear(in_features=embed_dim,out_features=num_classes))\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.cropping_layer(x)\n",
    "        cls_token = self.classtoken.expand(batch_size,-1,-1)\n",
    "        x = torch.cat((cls_token,x), dim=1)\n",
    "        x = self.positional_embedding + x #similar to NLP [CLS] [0][f1] [1][f2]\n",
    "        x = self.dropout(x)\n",
    "        x = self.encoders(x)\n",
    "        x = self.mlp(x[:,0])\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9dedbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_criterion, optimizer, epochs=25):\n",
    "\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(val_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/len(train) \n",
    "        avg_train_acc = train_acc/len(train) \n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/len(val)  \n",
    "        avg_valid_acc = valid_acc/len(val) \n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "                \n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%\".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100))\n",
    "        \n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b93bc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model,history \u001b[39m=\u001b[39m fit(ViT, criterion,optimizer)\n",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, loss_criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, epochs))\n\u001b[0;32m      9\u001b[0m \u001b[39m# Set to training mode\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     12\u001b[0m \u001b[39m# Loss and Accuracy within the epoch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: train() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "model,history = fit(ViT, criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.long).to(device)\n",
    "        \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
    "       \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96b1c524-89fb-4ce8-a49f-067fd489f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.long).to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
    "    \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ca85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {},
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4548cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2765 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(params \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m CFG[\u001b[39m\"\u001b[39m\u001b[39mLEARNING_RATE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, threshold_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mabs\u001b[39m\u001b[39m'\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-8\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m infer_model \u001b[39m=\u001b[39m train(model, optimizer, train_loader, val_loader, scheduler, device)\n",
      "Cell \u001b[1;32mIn[22], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_loader, val_loader, scheduler, device)\u001b[0m\n\u001b[0;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m output \u001b[39m=\u001b[39m model(imgs)\n\u001b[1;32m---> 19\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, labels)\n\u001b[0;32m     21\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     22\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1165\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1166\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "model = ViT(num_classes=len(df.columns)).to(device)\n",
    "model.eval()\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275a486-9c59-4b4e-80f6-5000e017b921",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ed16d0e-61ee-4737-b90a-3842860cc40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>./test/000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>./test/001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>./test/002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>./test/003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>./test/004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>TEST_787</td>\n",
       "      <td>./test/787.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>TEST_788</td>\n",
       "      <td>./test/788.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>TEST_789</td>\n",
       "      <td>./test/789.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>TEST_790</td>\n",
       "      <td>./test/790.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>TEST_791</td>\n",
       "      <td>./test/791.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        img_path\n",
       "0    TEST_000  ./test/000.png\n",
       "1    TEST_001  ./test/001.png\n",
       "2    TEST_002  ./test/002.png\n",
       "3    TEST_003  ./test/003.png\n",
       "4    TEST_004  ./test/004.png\n",
       "..        ...             ...\n",
       "787  TEST_787  ./test/787.png\n",
       "788  TEST_788  ./test/788.png\n",
       "789  TEST_789  ./test/789.png\n",
       "790  TEST_790  ./test/790.png\n",
       "791  TEST_791  ./test/791.png\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbbf9ae5-9d8c-4800-a809-63094a1e9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "378fd3a9-76d8-4c9a-81a1-c6a48492684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2866935c-407d-4919-a58b-1f8feaa66a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'infer_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds \u001b[39m=\u001b[39m inference(infer_model, test_loader, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'infer_model' is not defined"
     ]
    }
   ],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be0d25-6a06-43bb-bca0-94eda2409a26",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc864be2-c306-4ad0-aa97-1d5ab5ea9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472198d-6a2f-4d97-b45b-55031d6019a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada28d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>molding_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>TEST_787</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>TEST_788</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>TEST_789</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>TEST_790</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>TEST_791</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id           label\n",
       "0    TEST_000          damage\n",
       "1    TEST_001       pollution\n",
       "2    TEST_002          damage\n",
       "3    TEST_003  molding_repair\n",
       "4    TEST_004       pollution\n",
       "..        ...             ...\n",
       "787  TEST_787          damage\n",
       "788  TEST_788          damage\n",
       "789  TEST_789       pollution\n",
       "790  TEST_790       pollution\n",
       "791  TEST_791          damage\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result folder 생성\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "kst = timezone(timedelta(hours=9))\n",
    "train_serial =  datetime.now(kst).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "Record_path = os.path.join('result', train_serial)\n",
    "\n",
    "os.makedirs(Record_path, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af6d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>몰딩수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>TEST_787</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>TEST_788</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>TEST_789</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>TEST_790</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>TEST_791</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id label\n",
       "0    TEST_000    훼손\n",
       "1    TEST_001    오염\n",
       "2    TEST_002    훼손\n",
       "3    TEST_003  몰딩수정\n",
       "4    TEST_004    오염\n",
       "..        ...   ...\n",
       "787  TEST_787    훼손\n",
       "788  TEST_788    훼손\n",
       "789  TEST_789    오염\n",
       "790  TEST_790    오염\n",
       "791  TEST_791    훼손\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to map old column names to new column names\n",
    "name_map = dict(zip(new_names, ori_names))\n",
    "name_map\n",
    "\n",
    "\n",
    "# Rename columns using the rename() method\n",
    "submit_test = submit.replace(name_map)\n",
    "submit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e0511-2ce0-4658-893f-0f3641c50bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test.to_csv(os.path.join(Record_path,'submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f22bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>몰딩수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>TEST_787</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>TEST_788</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>TEST_789</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>TEST_790</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>TEST_791</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id label\n",
       "0    TEST_000    훼손\n",
       "1    TEST_001    오염\n",
       "2    TEST_002    훼손\n",
       "3    TEST_003  몰딩수정\n",
       "4    TEST_004    오염\n",
       "..        ...   ...\n",
       "787  TEST_787    훼손\n",
       "788  TEST_788    훼손\n",
       "789  TEST_789    오염\n",
       "790  TEST_790    오염\n",
       "791  TEST_791    훼손\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c98108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model information 저장\n",
    "import json\n",
    "model_info = {'CFG' : CFG, 'model' : str(model), 'optimizer' : str(optimizer), 'scheduler' : str(scheduler), 'train_serial' : train_serial}\n",
    "with open(os.path.join(Record_path,'model_info.json'), 'w') as f:\n",
    "    json.dump(model_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970a9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05852a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7aa453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69965500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c7a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
