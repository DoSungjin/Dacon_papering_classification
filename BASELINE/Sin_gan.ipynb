{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61ad9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install albumentations ;!pip3 install opencv-python ; !pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# torch.multiprocessing import\n",
    "from torch import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9614e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DoSungjin\\\\Documents\\\\GitHub\\\\Dacon_papering_classification\\\\DATA'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경로지정\n",
    "import os\n",
    "os.chdir('../DATA')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec1574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Set the device to CPU or GPU depending on availability\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':25,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {},
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2abecd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DoSungjin\\\\Documents\\\\GitHub\\\\Dacon_papering_classification\\\\DATA'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271f477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 데이터셋 디렉토리 경로\n",
    "dataset_dir = \"new_train\"\n",
    "\n",
    "# 모든 이미지 파일 경로 리스트\n",
    "all_img_list = []\n",
    "folder_list = []\n",
    "train_file_list = os.listdir(dataset_dir)\n",
    "for item in train_file_list:\n",
    "    item_path = os.path.join(dataset_dir, item)\n",
    "    for file in os.listdir(item_path):\n",
    "        all_img_list.append(os.path.join(item_path, file))\n",
    "        folder_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68163566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # folder name list\n",
    "ori_names = os.listdir('ori_train')\n",
    "\n",
    "new_names = ['furniture_repair', 'cleaning_mop_holder_repair', 'mold', 'twist', 'rust_contamination', 'wobbling', 'fabric_defect', 'molding_repair', 'stain', 'plaster_repair', 'pollution', 'typographical_error', 'crying', 'defective_joint', 'windowdoor_frame_repair', 'cracking', 'excessive_gap', 'piece', 'damage']\n",
    "\n",
    "# print(len(ori_names), len(new_names))\n",
    "# os.chdir('new_train')\n",
    "# # # folder rename\n",
    "# for ori_name, new_name in zip(ori_names, new_names):\n",
    "#     os.rename(ori_name, new_name)\n",
    "\n",
    "# print(os.listdir())\n",
    "# os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0d43a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n",
      "go on\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(ori_names, new_names):\n",
    "    len_a = len(os.listdir(f'ori_train/{a}'))\n",
    "    len_b = len(os.listdir(f'new_train/{b}'))\n",
    "    if len_a == len_b:\n",
    "        print('go on')\n",
    "    else: \n",
    "        print('stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4119733d-adef-436c-afca-4112a9225d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x : str(x).split('\\\\')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eb63d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\0.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\1.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\10.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\100.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\101.png</td>\n",
       "      <td>cleaning_mop_holder_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>new_train\\wobbling\\53.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>new_train\\wobbling\\6.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>new_train\\wobbling\\7.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>new_train\\wobbling\\8.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>new_train\\wobbling\\9.png</td>\n",
       "      <td>wobbling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          img_path                       label\n",
       "0       new_train\\cleaning_mop_holder_repair\\0.png  cleaning_mop_holder_repair\n",
       "1       new_train\\cleaning_mop_holder_repair\\1.png  cleaning_mop_holder_repair\n",
       "2      new_train\\cleaning_mop_holder_repair\\10.png  cleaning_mop_holder_repair\n",
       "3     new_train\\cleaning_mop_holder_repair\\100.png  cleaning_mop_holder_repair\n",
       "4     new_train\\cleaning_mop_holder_repair\\101.png  cleaning_mop_holder_repair\n",
       "...                                            ...                         ...\n",
       "3452                     new_train\\wobbling\\53.png                    wobbling\n",
       "3453                      new_train\\wobbling\\6.png                    wobbling\n",
       "3454                      new_train\\wobbling\\7.png                    wobbling\n",
       "3455                      new_train\\wobbling\\8.png                    wobbling\n",
       "3456                      new_train\\wobbling\\9.png                    wobbling\n",
       "\n",
       "[3457 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db41c93-3515-4fcd-936b-0a01f5388b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, stratify=df['label'], random_state=CFG['SEED'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb1f117e-105d-4e9e-b9bd-938d4271a940",
   "metadata": {},
   "source": [
    "## Label-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c8c5916-8065-4b5c-aa37-f3fb2b9fa422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\0.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\10.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\100.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new_train\\cleaning_mop_holder_repair\\101.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>new_train\\wobbling\\53.png</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>new_train\\wobbling\\6.png</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>new_train\\wobbling\\7.png</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>new_train\\wobbling\\8.png</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>new_train\\wobbling\\9.png</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          img_path  label\n",
       "0       new_train\\cleaning_mop_holder_repair\\0.png      0\n",
       "1       new_train\\cleaning_mop_holder_repair\\1.png      0\n",
       "2      new_train\\cleaning_mop_holder_repair\\10.png      0\n",
       "3     new_train\\cleaning_mop_holder_repair\\100.png      0\n",
       "4     new_train\\cleaning_mop_holder_repair\\101.png      0\n",
       "...                                            ...    ...\n",
       "3452                     new_train\\wobbling\\53.png     18\n",
       "3453                      new_train\\wobbling\\6.png     18\n",
       "3454                      new_train\\wobbling\\7.png     18\n",
       "3455                      new_train\\wobbling\\8.png     18\n",
       "3456                      new_train\\wobbling\\9.png     18\n",
       "\n",
       "[3457 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99368e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['label']==14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1f584b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>new_train\\stain\\0.png</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>new_train\\stain\\1.png</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>new_train\\stain\\2.png</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   img_path  label\n",
       "3021  new_train\\stain\\0.png     14\n",
       "3022  new_train\\stain\\1.png     14\n",
       "3023  new_train\\stain\\2.png     14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "            image = image.unsqueeze(0)\n",
    "            \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "340b4a8b-5d6c-413f-b8b6-066e91a660e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=10, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    ToTensorV2() \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# test_transform = A.Compose([\n",
    "#     A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "#     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "#     ToTensorV2()\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e87a8571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 618 x 697\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = 'new_train\\\\stain\\\\0.png'\n",
    "\n",
    "with Image.open(image_path) as img:\n",
    "    width, height = img.size\n",
    "\n",
    "print(f\"Image size: {width} x {height}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "# val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9db2130",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 94\u001b[0m\n\u001b[0;32m     92\u001b[0m optim_D\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     93\u001b[0m real_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((batch_size,), real_label, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m---> 94\u001b[0m output_real \u001b[39m=\u001b[39m discriminator(images)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     95\u001b[0m errD_real \u001b[39m=\u001b[39m criterion(output_real, real_labels)\n\u001b[0;32m     97\u001b[0m noise \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(batch_size, \u001b[39m100\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[26], line 60\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m     58\u001b[0m     \u001b[39m# Reshape the input tensor to have a shape of [batch_size, num_channels, height, width]\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain(\u001b[39minput\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\DoSungjin\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "import torchvision.utils as vutils\n",
    "\n",
    "\n",
    "# Step 2: Define the generator and discriminator models\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 100, 1, 1) # Reshape noise tensor to (batch_size, 100, 1, 1)\n",
    "        return self.main(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Reshape the input tensor to have a shape of [batch_size, num_channels, height, width]\n",
    "        input = input.view(-1, 3, 224, 224)\n",
    "        return self.main(input)\n",
    "    \n",
    "# Step 3: Set up the loss functions and optimizers\n",
    "ngpu = 1\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator(ngpu).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "lr = 0.0002\n",
    "optim_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optim_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Step 4: Create the training loop\n",
    "num_epochs = 20\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "output_dir = \"output\"\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        # Train the discriminator\n",
    "        optim_D.zero_grad()\n",
    "        real_labels = torch.full((batch_size,), real_label, device=device)\n",
    "        output_real = discriminator(images).view(-1).squeeze()\n",
    "        errD_real = criterion(output_real, real_labels)\n",
    "\n",
    "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, device=device)\n",
    "        output_fake = discriminator(fake_images.detach()).view(-1).squeeze()\n",
    "        errD_fake = criterion(output_fake, fake_labels)\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward()\n",
    "        optim_D.step()\n",
    "\n",
    "        # Train the generator\n",
    "        optim_G.zero_grad()\n",
    "        real_labels = torch.full((batch_size,), real_label, device=device)\n",
    "        output = discriminator(fake_images).view(-1).squeeze()\n",
    "        errG = criterion(output, real_labels)\n",
    "\n",
    "        errG.backward()\n",
    "        optim_G.step()\n",
    "\n",
    "        # Print losses\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[{epoch}/{num_epochs}] [{i}/{len(train_loader)}] Loss_D: {errD.item()} Loss_G: {errG.item()}\")\n",
    "\n",
    "        # Save generator's output periodically\n",
    "        if i % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake_images = generator(fixed_noise).detach().cpu()\n",
    "            img_list = vutils.make_grid(fake_images, padding=2, normalize=True)\n",
    "            vutils.save_image(img_list, os.path.join(output_dir, f\"fake_images_epoch_{epoch}_iter_{i}.png\"))\n",
    "\n",
    "    # Save model checkpoints\n",
    "    torch.save(generator.state_dict(), os.path.join(checkpoint_dir, f\"generator_epoch_{epoch}.pth\"))\n",
    "    torch.save(discriminator.state_dict(), os.path.join(checkpoint_dir, f\"discriminator_epoch_{epoch}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=len(le.classes_)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.efficientnet_b2(pretrained=True)\n",
    "        self.classifier = nn.Linear(1000, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eca35285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.long).to(device)\n",
    "        \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
    "       \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96b1c524-89fb-4ce8-a49f-067fd489f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.long).to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
    "    \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ca85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {},
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:45<00:00,  1.93it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [1.29716] Val Loss : [0.89246] Val Weighted F1 Score : [0.70932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:42<00:00,  2.03it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.56121] Val Loss : [0.82680] Val Weighted F1 Score : [0.74148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.98it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.29033] Val Loss : [1.00445] Val Weighted F1 Score : [0.74830]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:44<00:00,  1.98it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.19126] Val Loss : [0.95497] Val Weighted F1 Score : [0.77618]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.00it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.12779] Val Loss : [0.99275] Val Weighted F1 Score : [0.75776]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.01it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.13293] Val Loss : [1.16522] Val Weighted F1 Score : [0.73658]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.00it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.12970] Val Loss : [1.08762] Val Weighted F1 Score : [0.78190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.00it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.11537] Val Loss : [1.11700] Val Weighted F1 Score : [0.77720]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.01it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.09346] Val Loss : [1.18259] Val Weighted F1 Score : [0.76503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.98it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.08176] Val Loss : [1.19947] Val Weighted F1 Score : [0.76244]\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.98it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.04066] Val Loss : [1.10632] Val Weighted F1 Score : [0.80246]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.00it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.03181] Val Loss : [1.14340] Val Weighted F1 Score : [0.79270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.01it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.02908] Val Loss : [1.11847] Val Weighted F1 Score : [0.80759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.99it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.01406] Val Loss : [1.13184] Val Weighted F1 Score : [0.80611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.98it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.01181] Val Loss : [1.14337] Val Weighted F1 Score : [0.80221]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.01it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.01371] Val Loss : [1.14113] Val Weighted F1 Score : [0.80610]\n",
      "Epoch 00016: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.99it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.00784] Val Loss : [1.12393] Val Weighted F1 Score : [0.80833]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.99it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.00576] Val Loss : [1.12253] Val Weighted F1 Score : [0.80696]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.00it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.00461] Val Loss : [1.13822] Val Weighted F1 Score : [0.79914]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.99it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.00869] Val Loss : [1.14339] Val Weighted F1 Score : [0.79909]\n",
      "Epoch 00020: reducing learning rate of group 0 to 3.7500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.02it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.00250] Val Loss : [1.12902] Val Weighted F1 Score : [0.80245]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.00it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.00512] Val Loss : [1.15159] Val Weighted F1 Score : [0.80349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  2.00it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.00403] Val Loss : [1.13965] Val Weighted F1 Score : [0.80456]\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.8750e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.99it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.00292] Val Loss : [1.15358] Val Weighted F1 Score : [0.80239]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:43<00:00,  1.98it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.00397] Val Loss : [1.15605] Val Weighted F1 Score : [0.80327]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.eval()\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49a3544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# If you are using CUDA\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e275a486-9c59-4b4e-80f6-5000e017b921",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ed16d0e-61ee-4737-b90a-3842860cc40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>./test/000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>./test/001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>./test/002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>./test/003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>./test/004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>TEST_787</td>\n",
       "      <td>./test/787.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>TEST_788</td>\n",
       "      <td>./test/788.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>TEST_789</td>\n",
       "      <td>./test/789.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>TEST_790</td>\n",
       "      <td>./test/790.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>TEST_791</td>\n",
       "      <td>./test/791.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        img_path\n",
       "0    TEST_000  ./test/000.png\n",
       "1    TEST_001  ./test/001.png\n",
       "2    TEST_002  ./test/002.png\n",
       "3    TEST_003  ./test/003.png\n",
       "4    TEST_004  ./test/004.png\n",
       "..        ...             ...\n",
       "787  TEST_787  ./test/787.png\n",
       "788  TEST_788  ./test/788.png\n",
       "789  TEST_789  ./test/789.png\n",
       "790  TEST_790  ./test/790.png\n",
       "791  TEST_791  ./test/791.png\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbbf9ae5-9d8c-4800-a809-63094a1e9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "378fd3a9-76d8-4c9a-81a1-c6a48492684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2866935c-407d-4919-a58b-1f8feaa66a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:07<00:00,  3.44it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35be0d25-6a06-43bb-bca0-94eda2409a26",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc864be2-c306-4ad0-aa97-1d5ab5ea9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a472198d-6a2f-4d97-b45b-55031d6019a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eada28d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>molding_repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>TEST_787</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>TEST_788</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>TEST_789</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>TEST_790</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>TEST_791</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id           label\n",
       "0    TEST_000          damage\n",
       "1    TEST_001       pollution\n",
       "2    TEST_002          damage\n",
       "3    TEST_003  molding_repair\n",
       "4    TEST_004       pollution\n",
       "..        ...             ...\n",
       "787  TEST_787          damage\n",
       "788  TEST_788          damage\n",
       "789  TEST_789       pollution\n",
       "790  TEST_790       pollution\n",
       "791  TEST_791          damage\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "367e2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result folder 생성\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "kst = timezone(timedelta(hours=9))\n",
    "train_serial =  datetime.now(kst).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "Record_path = os.path.join('result', train_serial)\n",
    "\n",
    "os.makedirs(Record_path, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3af6d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>몰딩수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>TEST_787</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>TEST_788</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>TEST_789</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>TEST_790</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>TEST_791</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id label\n",
       "0    TEST_000    훼손\n",
       "1    TEST_001    오염\n",
       "2    TEST_002    훼손\n",
       "3    TEST_003  몰딩수정\n",
       "4    TEST_004    오염\n",
       "..        ...   ...\n",
       "787  TEST_787    훼손\n",
       "788  TEST_788    훼손\n",
       "789  TEST_789    오염\n",
       "790  TEST_790    오염\n",
       "791  TEST_791    훼손\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to map old column names to new column names\n",
    "name_map = dict(zip(new_names, ori_names))\n",
    "name_map\n",
    "\n",
    "\n",
    "# Rename columns using the rename() method\n",
    "submit_test = submit.replace(name_map)\n",
    "submit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e3e0511-2ce0-4658-893f-0f3641c50bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test.to_csv(os.path.join(Record_path,'submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "376f22bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>몰딩수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>TEST_787</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>TEST_788</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>TEST_789</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>TEST_790</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>TEST_791</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id label\n",
       "0    TEST_000    훼손\n",
       "1    TEST_001    오염\n",
       "2    TEST_002    훼손\n",
       "3    TEST_003  몰딩수정\n",
       "4    TEST_004    오염\n",
       "..        ...   ...\n",
       "787  TEST_787    훼손\n",
       "788  TEST_788    훼손\n",
       "789  TEST_789    오염\n",
       "790  TEST_790    오염\n",
       "791  TEST_791    훼손\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42c98108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model information 저장\n",
    "import json\n",
    "model_info = {'CFG' : CFG, 'model' : str(model), 'optimizer' : str(optimizer), 'scheduler' : str(scheduler), 'train_serial' : train_serial}\n",
    "with open(os.path.join(Record_path,'model_info.json'), 'w') as f:\n",
    "    json.dump(model_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970a9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05852a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7aa453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69965500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c7a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
